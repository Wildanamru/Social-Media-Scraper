# tiktok.py
# Streamlit TikTok scraper (yt-dlp)
# - Persist preview (st.session_state)
# - Filter tanggal
# - Cookies JSON/TXT (JSON juga dipakai untuk fetch thumbnail -> anti putih)
# - Download CSV
# - Download Excel (thumbnail tertanam)
#
# pip install yt-dlp pandas requests pillow openpyxl

import os
import io
import json
import tempfile
import hashlib
from datetime import datetime, timedelta, date
from typing import List, Dict, Any, Optional, Tuple

import pandas as pd
import requests
import streamlit as st
from yt_dlp import YoutubeDL
from PIL import Image as PILImage

from openpyxl import Workbook
from openpyxl.drawing.image import Image as XLImage
from openpyxl.styles import Font, Alignment

UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0.0.0 Safari/537.36"
)

# --------------------- Helpers umum ---------------------
def _parse_date(entry: Dict[str, Any]) -> Optional[str]:
    ts = entry.get("timestamp")
    if ts is not None:
        try:
            return datetime.fromtimestamp(int(float(ts))).strftime("%Y-%m-%d %H:%M")
        except Exception:
            pass
    up = entry.get("upload_date")
    if up:
        try:
            dt = datetime.strptime(str(up), "%Y%m%d")
            return dt.strftime("%Y-%m-%d 00:00")
        except Exception:
            pass
    return None

def _get_thumb_url(entry: Dict[str, Any]) -> Optional[str]:
    if entry.get("thumbnail"):
        return entry["thumbnail"]
    thumbs = entry.get("thumbnails") or []
    if isinstance(thumbs, list) and thumbs:
        return (thumbs[-1] or {}).get("url")
    return None

def _get_int(entry: Dict[str, Any], *keys: str) -> Optional[int]:
    for k in keys:
        v = entry.get(k)
        if isinstance(v, (int, float)) and not pd.isna(v):
            return int(v)
    return None

def _normalize_row(entry: Dict[str, Any]) -> Dict[str, Any]:
    return {
        "Tanggal Post": _parse_date(entry),
        "Gambar": _get_thumb_url(entry),     # URL (nanti diubah ke bytes utk preview)
        "Link Post": entry.get("webpage_url") or entry.get("url"),
        "Caption": entry.get("title") or entry.get("description"),
        "Like": _get_int(entry, "like_count", "likes"),
        "Views": _get_int(entry, "view_count", "views", "play_count"),
        "Comments": _get_int(entry, "comment_count", "comments"),
        "Shares": _get_int(entry, "repost_count", "share_count", "shares"),
    }

def build_dataframe(entries: List[Dict[str, Any]]) -> pd.DataFrame:
    rows = [_normalize_row(e) for e in entries]
    df = pd.DataFrame(
        rows,
        columns=["Tanggal Post", "Gambar", "Link Post", "Caption", "Like", "Views", "Comments", "Shares"],
    )
    if df["Tanggal Post"].notna().any():
        df["__dt"] = pd.to_datetime(df["Tanggal Post"], errors="coerce")
        df = df.sort_values("__dt", ascending=False)
        df["Tanggal Post"] = df["__dt"].dt.strftime("%Y-%m-%d %H:%M")
        df = df.drop(columns="__dt")
    return df

def write_netscape_from_json(json_bytes: bytes) -> str:
    data = json.loads(json_bytes.decode("utf-8"))
    if not isinstance(data, list):
        raise ValueError("Format cookies JSON tidak valid: harus list of objects")
    fd, path = tempfile.mkstemp(prefix="tiktok_cookies_", suffix=".txt")
    os.close(fd)
    with open(path, "w", encoding="utf-8") as f:
        f.write("# Netscape HTTP Cookie File\n")
        f.write("# Generated by Streamlit module (TikTok).\n")
        for c in data:
            domain = c.get("domain") or c.get("host") or ""
            if not domain:
                continue
            include_subdomains = "TRUE" if (domain.startswith(".") or (c.get("hostOnly") is False)) else "FALSE"
            path_cookie = c.get("path") or "/"
            secure = "TRUE" if c.get("secure") else "FALSE"
            exp_raw = c.get("expirationDate")
            if exp_raw is None or c.get("session"):
                expires = 0
            else:
                try:
                    expires = int(float(exp_raw))
                except Exception:
                    expires = 0
            name = str(c.get("name", ""))
            value = str(c.get("value", ""))
            f.write(f"{domain}\t{include_subdomains}\t{path_cookie}\t{secure}\t{expires}\t{name}\t{value}\n")
    return path

def _cookies_dict_from_json_bytes(cookie_json_bytes: Optional[bytes]) -> Dict[str, str]:
    out: Dict[str, str] = {}
    if not cookie_json_bytes:
        return out
    try:
        arr = json.loads(cookie_json_bytes.decode("utf-8"))
        if isinstance(arr, list):
            for c in arr:
                name, value = c.get("name"), c.get("value")
                if name and value:
                    out[name] = value
    except Exception:
        pass
    return out

def _fetch_thumbnail_png_bytes(url: str, referer_url: Optional[str], cookie_json_bytes: Optional[bytes], target_w: int = 120) -> Optional[bytes]:
    if not url:
        return None
    headers = {
        "User-Agent": UA,
        "Referer": referer_url or "https://www.tiktok.com/",
        "Accept": "image/avif,image/webp,image/apng,image/*,*/*;q=0.8",
        "Accept-Language": "id-ID,id;q=0.9,en-US;q=0.8,en;q=0.7",
    }
    cookies = _cookies_dict_from_json_bytes(cookie_json_bytes)
    try:
        resp = requests.get(url, headers=headers, cookies=cookies, timeout=20)
        resp.raise_for_status()
        img = PILImage.open(io.BytesIO(resp.content))
        # Komposit alpha → putih
        if img.mode == "RGBA":
            bg = PILImage.new("RGB", img.size, (255, 255, 255))
            bg.paste(img, mask=img.split()[3])
            img = bg
        elif img.mode != "RGB":
            img = img.convert("RGB")
        # Resize kecil untuk preview
        w0, h0 = img.size
        if w0 > 0 and target_w:
            scale = target_w / float(w0)
            img = img.resize((int(w0 * scale), int(h0 * scale)))
        bio = io.BytesIO()
        img.save(bio, format="PNG")
        bio.seek(0)
        return bio.getvalue()
    except Exception:
        return None

def build_preview_df_and_images(df_url: pd.DataFrame, cookie_json_bytes: Optional[bytes]) -> Tuple[pd.DataFrame, List[bytes]]:
    df_prev = df_url.copy()
    imgs: List[bytes] = []
    for _, row in df_url.iterrows():
        url = row.get("Gambar")
        ref = row.get("Link Post") or "https://www.tiktok.com/"
        png = _fetch_thumbnail_png_bytes(url, ref, cookie_json_bytes, target_w=120)
        imgs.append(png if png is not None else b"")
    df_prev["Gambar"] = imgs  # bytes → tampil di ImageColumn tanpa hotlink
    return df_prev, imgs

def make_excel_with_images(df_meta: pd.DataFrame, preloaded_images: Optional[List[bytes]]) -> bytes:
    wb = Workbook()
    ws = wb.active
    ws.title = "TikTok"

    headers = ["Tanggal Post", "Gambar", "Link Post", "Caption", "Like", "Views", "Comments", "Shares"]
    ws.append(headers)

    for col_idx in range(1, len(headers) + 1):
        ws.cell(row=1, column=col_idx).font = Font(bold=True)
    widths = [18, 20, 45, 60, 12, 12, 12, 12]
    for idx, w in enumerate(widths, start=1):
        ws.column_dimensions[chr(64 + idx)].width = w

    for i, row in enumerate(df_meta.itertuples(index=False), start=2):
        row_dict = dict(zip(df_meta.columns, row))
        ws.cell(i, 1, row_dict.get("Tanggal Post"))
        link_url = row_dict.get("Link Post")
        link_cell = ws.cell(i, 3, "Buka")
        if link_url:
            link_cell.hyperlink = link_url
            try:
                link_cell.style = "Hyperlink"
            except Exception:
                pass
        cap_cell = ws.cell(i, 4, row_dict.get("Caption"))
        cap_cell.alignment = Alignment(wrap_text=True, vertical="top")
        ws.cell(i, 5, row_dict.get("Like"))
        ws.cell(i, 6, row_dict.get("Views"))
        ws.cell(i, 7, row_dict.get("Comments"))
        ws.cell(i, 8, row_dict.get("Shares"))

        # Pakai image bytes yang sama dengan preview (konsisten; anti putih)
        png_bytes = None
        if preloaded_images and len(preloaded_images) >= (i - 1):
            png_bytes = preloaded_images[i - 2]
        if png_bytes:
            buf = io.BytesIO(png_bytes); buf.seek(0); buf.name = "thumb.png"
            xl_img = XLImage(buf)
            ws.add_image(xl_img, f"B{i}")
            try:
                im = PILImage.open(io.BytesIO(png_bytes))
                ws.row_dimensions[i].height = max(ws.row_dimensions[i].height or 0, im.size[1] * 0.75)
            except Exception:
                ws.row_dimensions[i].height = max(ws.row_dimensions[i].height or 0, 90)

    out = io.BytesIO()
    wb.save(out); out.seek(0)
    return out.getvalue()

def fetch_user_videos(user: str, limit: int, cookies_path: Optional[str] = None) -> List[Dict[str, Any]]:
    profile_url = f"https://www.tiktok.com/@{user}"
    ydl_opts = {
        "quiet": True,
        "skip_download": True,
        "extract_flat": False,
        "ignoreerrors": True,
        "playlistend": limit,
        "http_headers": {"User-Agent": UA},
    }
    if cookies_path:
        ydl_opts["cookiefile"] = cookies_path

    entries: List[Dict[str, Any]] = []
    with YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(profile_url, download=False)
        if not info:
            return []
        if isinstance(info, dict) and "entries" in info and isinstance(info["entries"], list):
            for ent in info["entries"]:
                if len(entries) >= limit:
                    break
                if ent is None:
                    continue
                if ent.get("_type") == "url" and ent.get("url"):
                    try:
                        vinfo = ydl.extract_info(ent["url"], download=False)
                        if vinfo:
                            entries.append(vinfo)
                    except Exception:
                        continue
                else:
                    entries.append(ent)
        else:
            entries.append(info)
    return entries[:limit]

def apply_date_filter(df: pd.DataFrame, start_d: Optional[date], end_d: Optional[date]) -> pd.DataFrame:
    if start_d is None or end_d is None or df.empty:
        return df
    sdt = pd.to_datetime(start_d.strftime("%Y-%m-%d") + " 00:00")
    edt = pd.to_datetime(end_d.strftime("%Y-%m-%d") + " 23:59:59")
    tmp = df.copy()
    tmp["__dt"] = pd.to_datetime(tmp["Tanggal Post"], errors="coerce")
    tmp = tmp[(tmp["__dt"] >= sdt) & (tmp["__dt"] <= edt)]
    tmp = tmp.drop(columns="__dt")
    return tmp

# --------------------- UI/MAIN ---------------------
def render_app(key_prefix: str = "tt_"):
    st.subheader("🎵 TikTok Scraper")

    # --- Sidebar kecil khusus TikTok (pakai prefix biar aman antar modul) ---
    with st.sidebar:
        st.markdown("---")
        st.markdown("**Pengaturan TikTok**")
        username = st.text_input("Username (tanpa @)", key=f"{key_prefix}username", placeholder="mis: viralkan.id")
        max_videos = st.slider("Maksimal video", 5, 300, 60, 5, key=f"{key_prefix}max")
        use_date_filter = st.checkbox("Gunakan filter tanggal", value=False, key=f"{key_prefix}use_date")
        if use_date_filter:
            today = date.today()
            default_start = today - timedelta(days=90)
            start_date, end_date = st.date_input(
                "Rentang tanggal", value=(default_start, today), key=f"{key_prefix}daterange"
            )
        else:
            start_date = end_date = None

        cookie_file = st.file_uploader(
            "Cookie TikTok (opsional) – .json (Chrome/extension) & .txt (Netscape)",
            type=["json", "txt"],
            key=f"{key_prefix}cookie",
        )
        start_btn = st.button("🚀 Scrape Sekarang", use_container_width=True, key=f"{key_prefix}go")

    # --- Init session_state scoped by prefix ---
    for k in ("df_meta", "last_username", "cookie_path", "cookie_json_bytes"):
        st.session_state.setdefault(f"{key_prefix}{k}", None)

    # --- On click: scrape & store ---
    if start_btn:
        if not (username or "").strip():
            st.error("Masukkan username TikTok terlebih dahulu.")
        else:
            try:
                cookie_path = None
                cookie_json_bytes: Optional[bytes] = None

                if cookie_file is not None:
                    suffix = os.path.splitext(cookie_file.name)[1].lower()
                    if suffix == ".json":
                        cookie_json_bytes = cookie_file.read()                         # utk fetch thumbnail
                        cookie_path = write_netscape_from_json(cookie_json_bytes)       # utk yt-dlp
                    elif suffix == ".txt":
                        fd, cookie_path = tempfile.mkstemp(prefix="tiktok_cookies_raw_", suffix=".txt")
                        os.close(fd)
                        with open(cookie_path, "wb") as f:
                            f.write(cookie_file.read())
                        cookie_json_bytes = None

                with st.spinner("Mengambil data…"):
                    entries = fetch_user_videos((username or "").strip().lstrip("@"), max_videos, cookie_path)

                if not entries:
                    st.warning("Tidak ada data yang bisa diambil. Coba unggah cookies, ganti jaringan, atau kurangi limit.")
                else:
                    df_meta = build_dataframe(entries)      # kolom Gambar = URL
                    st.session_state[f"{key_prefix}df_meta"] = df_meta
                    st.session_state[f"{key_prefix}last_username"] = (username or "").strip().lstrip("@")
                    st.session_state[f"{key_prefix}cookie_path"] = cookie_path
                    st.session_state[f"{key_prefix}cookie_json_bytes"] = cookie_json_bytes
            except Exception as e:
                st.error(f"Gagal mengambil data: {e}")

    # --- Always render preview if we have data ---
    df_meta = st.session_state.get(f"{key_prefix}df_meta")
    if df_meta is None:
        st.info("Masukkan username lalu klik **Scrape Sekarang** untuk melihat preview.")
        return

    df_show = df_meta
    if start_date and end_date:
        df_show = apply_date_filter(df_show, start_date, end_date)
        if df_show.empty:
            st.info("Tidak ada video dalam rentang/filter yang dipilih.")
            return

    # Build preview bytes (anti putih) + Excel bytes
    cookie_json_bytes = st.session_state.get(f"{key_prefix}cookie_json_bytes")
    df_preview, preloaded_imgs = build_preview_df_and_images(df_show, cookie_json_bytes)

    st.success(f"Berhasil! Ditemukan {len(df_preview)} video untuk @{st.session_state.get(f'{key_prefix}last_username','user')}.")
    st.dataframe(
        df_preview,
        use_container_width=True,
        column_config={
            "Gambar": st.column_config.ImageColumn("Gambar"),
            "Link Post": st.column_config.LinkColumn("Link Post"),
            "Like": st.column_config.NumberColumn("Like", format="%,d"),
            "Views": st.column_config.NumberColumn("Views", format="%,d"),
            "Comments": st.column_config.NumberColumn("Comments", format="%,d"),
            "Shares": st.column_config.NumberColumn("Shares", format="%,d"),
        },
    )

    # Unduhan
    csv_bytes = df_show.to_csv(index=False).encode("utf-8")
    st.download_button(
        "💾 Download CSV",
        data=csv_bytes,
        file_name=f"tiktok_{st.session_state.get(f'{key_prefix}last_username','user')}.csv",
        mime="text/csv",
        use_container_width=True,
        key=f"{key_prefix}dl_csv",
    )

    xlsx_bytes = make_excel_with_images(df_show, preloaded_images=preloaded_imgs)
    st.download_button(
        "📥 Download Excel (XLSX, dengan thumbnail)",
        data=xlsx_bytes,
        file_name=f"tiktok_{st.session_state.get(f'{key_prefix}last_username','user')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        use_container_width=True,
        key=f"{key_prefix}dl_xlsx",
    )

    # Duplikasi tombol Excel di sidebar (biar gampang dicari)
    st.sidebar.download_button(
        "📥 Download Excel (TikTok)",
        data=xlsx_bytes,
        file_name=f"tiktok_{st.session_state.get(f'{key_prefix}last_username','user')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key=f"{key_prefix}dl_xlsx_sidebar",
    )

    with st.expander("ℹ️ Rincian Teknis"):
        st.markdown(
            """
- Metadata diambil via **yt-dlp** dari profil (tanpa API resmi).
- Gambar: thumbnail di-*fetch* server-side (pakai **Referer** + cookies JSON kalau ada) ⇒ menghindari gambar putih.
- Download Excel menanam thumbnail (PNG) langsung ke workbook; kolom **Link Post** berisi hyperlink “Buka”.
            """
        )
